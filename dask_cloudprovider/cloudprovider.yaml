cloudprovider:
  ecs:
    fargate_scheduler: False # Use fargate mode for the scheduler
    fargate_workers: False # Use fargate mode for the workers
    scheduler_cpu: 1024 # Millicpu (1024ths of a CPU core)
    scheduler_mem: 4096 # Memory in MB
    #   scheduler_extra_args: "--tls-cert,/path/to/cert.pem,--tls-key,/path/to/cert.key,--tls-ca-file,/path/to/ca.key"
    worker_cpu: 4096 # Millicpu (1024ths of a CPU core)
    worker_mem: 16384 # Memory in MB
    worker_gpu: 0 # Number of GPUs for each worker
    #   worker_extra_args: "--tls-cert,/path/to/cert.pem,--tls-key,/path/to/cert.key,--tls-ca-file,/path/to/ca.key"
    n_workers: 0 # Number of workers to start the cluster with
    scheduler_timeout: "5 minutes" # Length of inactivity to wait before closing the cluster

    image: "daskdev/dask:latest" # Docker image to use for non GPU tasks
    gpu_image: "rapidsai/rapidsai:latest" # Docker image to use for GPU tasks
    cluster_name_template: "dask-{uuid}" # Template to use when creating a cluster
    cluster_arn: "" # ARN of existing ECS cluster to use (if not set one will be created)
    execution_role_arn: "" # Arn of existing execution role to use (if not set one will be created)
    task_role_arn: "" # Arn of existing task role to use (if not set one will be created)
    task_role_policies: [] # List of policy arns to attach to tasks (e.g S3 read only access)
    #   platform_version: "LATEST" # Fargate platformVersion string like "1.4.0" or "LATEST"

    cloudwatch_logs_group: "" # Name of existing cloudwatch logs group to use (if not set one will be created)
    cloudwatch_logs_stream_prefix: "{cluster_name}" # Stream prefix template
    cloudwatch_logs_default_retention: 30 # Number of days to retain logs (only applied if not using existing group)

    vpc: "default" # VPC to use for tasks
    subnets: [] # VPC subnets to use (will use all available if not set)
    security_groups: [] # Security groups to use (if not set one will be created)

    tags: {} # Tags to apply to all AWS resources created by the cluster manager
    environment: {} # Environment variables that are set within a task container
    find_address_timeout: 60 # Configurable timeout in seconds for finding the task IP from the cloudwatch logs.
    skip_cleanup: False # Skip cleaning up of stale resources

  ec2:
    region: null # AWS region to create cluster. Defaults to environment or account default region.
    bootstrap: true # It is assumed that the AMI does not have Docker and needs bootstrapping. Set this to false if using a custom AMI with Docker already installed.
    auto_shutdown: true # Shutdown instances automatically if the scheduler or worker services time out.
    # worker_command: "dask-worker" # The command for workers to run. If the instance_type is a GPU instance dask-cuda-worker will be used.
    # ami: "" # AMI ID to use for all instances. Defaults to latest Ubuntu 20.04 image.
    instance_type: "t2.micro" # Instance type for all workers
    docker_image: "daskdev/dask:latest" # docker image to use
    # vpc: "" # VPC id for instances to join. Defaults to default VPC.
    # subnet_id: "" # Subnet ID for instances to. Defaults to all subnets in default VPC.
    # security_groups: [] # Security groups for instances. Will create a minimal Dask security group by default.
    filesystem_size: 40 # Default root filesystem size for scheduler and worker VMs in GB

  azure:
    location: null # The Azure location to launch your cluster
    resource_group: null # The Azure resource group for the cluster
    azureml:
      experiment_name: "dask-cloudprovider" # default name of the Experiment to submit
      initial_node_count: 1 # Initial node count
      jupyter: False # by default start the Jupyter lab instance on the headnode
      jupyter_port: 9000 # default Jupyter lab port on the headnode
      dashboard_port: 9001 # default Dask dashboard port on the headnode
      scheduler_port: 9002 # default for the scheduler port if using from outside of cluster VNET
      scheduler_idle_timeout: 1200 # default timeout for dask-scheduler process to shutdown if idle (in seconds)
      worker_death_timeout: 30 # default timeout for dask-worker process upon losing scheduler
      additional_ports: [] # list of tuples of additional ports to map/forward
      admin_username: "" # username to log in to the AzureML Training Cluster for 'local' runs
      admin_ssh_key: "" # password to log in to the AzureML Training Cluster for 'local' runs
      telemetry_opt_out: False # by default we log the version of the AzureMLCluster being used, set to True to opt-out
      datastores: [] # default list of datastores to mount
    azurevm:
      resource_group: null # Azure resource group
      vnet: null # Azure Virtual Network to launch VMs in
      security_group: null # Network security group to allow 8786 and 8787
      public_ingress: true # Assign a public IP address to the scheduler
      vm_size: "Standard_DS1_v2" # Azure VM size to use for scheduler and workers
      scheduler_vm_size: null # Set a different VM size for the scheduler. Will use vm_size if not set
      docker_image: "daskdev/dask:latest" # docker image to use
      vm_image: # OS image to use for the virtual machines
        publisher: "Canonical"
        offer: "UbuntuServer"
        sku: "18.04-LTS"
        version: "latest"
      bootstrap: true # It is assumed that the VHD does not have Docker and needs bootstrapping. Set this to false if using a custom VHD with Docker already installed.
      auto_shutdown: true # Shutdown instances automatically if the scheduler or worker services time out.

  digitalocean:
    token: null # API token for interacting with the Digital Ocean API
    region: "nyc3" # Region to launch Droplets in
    size: "s-1vcpu-1gb" # Droplet size to launch, default is 1GB RAM, 1 vCPU
    image: "ubuntu-20-04-x64" # Operating System image to use

  gcp:
    source_image: "projects/ubuntu-os-cloud/global/images/ubuntu-minimal-1804-bionic-v20201014" # the gcp image to use for all instances
    zone: "us-east1-c" # the zone of of where to launch the instances
    projectid: "" # name of the google cloud project
    machine_type: "n1-standard-1" # size of the machine type to use
    filesystem_size: 50 # amount in GBs of hard drive space to allocate
    ngpus: "" # number of GPUs to use
    gpu_type: "" # type of gpus to use: nvidia-tesla-k80, nvidia-tesla-p100, nvidia-tesla-t4
    docker_image: "daskdev/dask:latest" # docker image to use
    auto_shutdown: true # Shutdown instances automatically if the scheduler or worker services time out.
    public_ingress: true # configure the scheduler to be externally accessible.  This assumes firefwall rules for 8787 and 8786
