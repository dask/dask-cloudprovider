cloudprovider:
  ecs:
    fargate_scheduler: False # Use fargate mode for the scheduler
    fargate_workers: False # Use fargate mode for the workers
    scheduler_cpu: 1024 # Millicpu (1024ths of a CPU core)
    scheduler_mem: 4096 # Memory in MB
#   scheduler_extra_args: "--tls-cert,/path/to/cert.pem,--tls-key,/path/to/cert.key,--tls-ca-file,/path/to/ca.key"
    worker_cpu: 4096 # Millicpu (1024ths of a CPU core)
    worker_mem: 16384 # Memory in MB
    worker_gpu: 0 # Number of GPUs for each worker
#   worker_extra_args: "--tls-cert,/path/to/cert.pem,--tls-key,/path/to/cert.key,--tls-ca-file,/path/to/ca.key"
    n_workers: 0 # Number of workers to start the cluster with
    scheduler_timeout: "5 minutes" # Length of inactivity to wait before closing the cluster

    image: "daskdev/dask:latest" # Docker image to use for non GPU tasks
    gpu_image: "rapidsai/rapidsai:latest" # Docker image to use for GPU tasks
    cluster_name_template: "dask-{uuid}" # Template to use when creating a cluster
    cluster_arn: "" # ARN of existing ECS cluster to use (if not set one will be created)
    execution_role_arn: "" # Arn of existing execution role to use (if not set one will be created)
    task_role_arn: "" # Arn of existing task role to use (if not set one will be created)
    task_role_policies: [] # List of policy arns to attach to tasks (e.g S3 read only access)
#   platform_version: "LATEST" # Fargate platformVersion string like "1.4.0" or "LATEST"

    cloudwatch_logs_group: "" # Name of existing cloudwatch logs group to use (if not set one will be created)
    cloudwatch_logs_stream_prefix: "{cluster_name}" # Stream prefix template
    cloudwatch_logs_default_retention: 30 # Number of days to retain logs (only applied if not using existing group)

    vpc: "default" # VPC to use for tasks
    subnets: [] # VPC subnets to use (will use all available if not set)
    security_groups: [] # Security groups to use (if not set one will be created)

    tags: {} # Tags to apply to all AWS resources created by the cluster manager
    environment: {} # Environment variables that are set within a task container
    find_address_timeout: 60 # Configurable timeout in seconds for finding the task IP from the cloudwatch logs.
    skip_cleanup: False # Skip cleaning up of stale resources
  azure:
    experiment_name: "dask-cloudprovider" # default name of the Experiment to submit
    initial_node_count: 1 # Initial node count
    jupyter: False # by default start the Jupyter lab instance on the headnode
    jupyter_port: 9000 # default Jupyter lab port on the headnode
    dashboard_port: 9001 # default Dask dashboard port on the headnode
    scheduler_port: 9002 # default for the scheduler port if using from outside of cluster VNET
    scheduler_idle_timeout: 1200 # default timeout for dask-scheduler process to shutdown if idle (in seconds)
    worker_death_timeout: 30 # default timeout for dask-worker process upon losing scheduler
    additional_ports: [] # list of tuples of additional ports to map/forward
    admin_username: "" # username to log in to the AzureML Training Cluster for 'local' runs
    admin_ssh_key: "" # password to log in to the AzureML Training Cluster for 'local' runs
    telemetry_opt_out: False # by default we log the version of the AzureMLCluster being used, set to True to opt-out 
    datastores: [] # default list of datastores to mount
